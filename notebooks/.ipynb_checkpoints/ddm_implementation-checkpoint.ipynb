{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport likelihood\n",
    "\n",
    "import likelihood as lh\n",
    "import ddm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Plotting settings \n",
    "mpl.rcParams['font.size'] = 18\n",
    "mpl.rcParams['legend.fontsize'] = 'large'\n",
    "mpl.rcParams['figure.titlesize'] = 'medium'\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['figure.figsize'] = [13,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_files = glob.glob('inference_results/*.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_probs = {}\n",
    "for file in location_files:\n",
    "    with open(file, 'rb') as f:\n",
    "        fname = file.split('/')[-1]\n",
    "        location_probs[fname] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location_probs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(location_probs.keys())\n",
    "location_probs[keys[0]].shape\n",
    "\n",
    "plt.imshow(location_probs[keys[0]][60,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_train(location_dict, n_samples=100, basis_length=5):\n",
    "    basis = []\n",
    "    test = []\n",
    "    for i in range(n_samples):\n",
    "        loc = np.random.choice(list(location_dict.keys()))\n",
    "        \n",
    "        start = np.random.choice(np.arange(location_dict[loc].shape[0]-basis_length-1))\n",
    "        basis += [location_dict[loc][start:start+basis_length]]\n",
    "        test += [location_dict[loc][start+basis_length+1]]\n",
    "    basis = np.stack(basis)\n",
    "    basis = tf.convert_to_tensor(basis, dtype=float)\n",
    "    basis = tf.reshape(basis, [basis.shape[0], basis.shape[1], basis.shape[2], basis.shape[3], 1])\n",
    "    \n",
    "    test = np.stack(test)\n",
    "    test = tf.convert_to_tensor(test, dtype=float)\n",
    "    test = tf.reshape(test, [test.shape[0], 1, test.shape[1], test.shape[2], 1])\n",
    "    \n",
    "    return basis, test         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_length = 10\n",
    "\n",
    "X, y = compile_train(location_probs, n_samples=500, basis_length=basis_length) \n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = 'none'\n",
    "model = ddm.fit_observation(X, y, num_steps=2000, learning_rate=0.001,\n",
    "                            reg=0.01, normalization=normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might want to mess with reg until we get stable values here\n",
    "model['gamma'].numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(model['loss'])), model['loss'])\n",
    "ax=plt.gca()\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ddm.predict(model['gamma'], X, normalization=normalization,\n",
    "                   mean=model['mean'], std=model['std'])\n",
    "if normalization == 'global' or normalization == 'local':\n",
    "    true, mean, std = ddm.normalize(y, method=normalization,\n",
    "                                    mean=model['mean'], std=model['std'])\n",
    "    true = true[:, 0, :, :, :]\n",
    "else:\n",
    "    true = y[:, 0, :, :, :]\n",
    "\n",
    "print('total loss', tf.math.reduce_sum(tf.abs(pred-true)))\n",
    "\n",
    "for i in range(10):\n",
    "    p = pred[i, :, :, 0]\n",
    "    plt.imshow(p)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(true[i, :, :, 0])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(abs(pred[i, :, :, 0] - true[i, :, :, 0]) / model['rmse'])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_map.shape, hot_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_map = ddm.hot_detect(model['gamma'], basis=X, test=y, rmse=model['rmse'],\n",
    "                         normalization=normalization, mean=model['mean'], std=model['std'],\n",
    "                         reduce=False)\n",
    "hot_score = ddm.hot_detect(model['gamma'], basis=X, test=y, rmse=model['rmse'],\n",
    "                         normalization=normalization, mean=model['mean'], std=model['std'],\n",
    "                         reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = np.argsort(hot_score)[::-1]\n",
    "for i in order[:5]:\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "    f.suptitle(f'hot score: {hot_score[i]: .2e}')\n",
    "    f.tight_layout()\n",
    "    \n",
    "    pre = tf.math.reduce_sum(X[i], axis=[0, -1])\n",
    "    ax1.imshow(pre) #vmin=0, vmax=1)\n",
    "    ax1.set_title('pre')\n",
    "    #plt.colorbar(im, ax=ax1, shrink=0.3)\n",
    "    \n",
    "    post = tf.math.reduce_sum(y[i], axis=[0, -1])\n",
    "    ax2.imshow(post)# vmin=0, vmax=1)\n",
    "    ax2.set_title('post')\n",
    "    \n",
    "    im = ax3.imshow(hot_map[i, 0, :, :, 0], vmin=0, vmax=5)\n",
    "    ax3.set_title('anomaly')\n",
    "    plt.colorbar(im, ax=ax3, shrink=0.3)\n",
    "    \n",
    "    plt.subplots_adjust(top=1.25)\n",
    "    plt.show()\n",
    "    \n",
    "for i in order[-5:]:\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "    f.suptitle(f'hot score: {hot_score[i]: .2e}')\n",
    "    f.tight_layout()\n",
    "    \n",
    "    pre = tf.math.reduce_sum(X[i], axis=[0, -1])\n",
    "    ax1.imshow(pre)#, vmin=0, vmax=1)\n",
    "    ax1.set_title('pre')\n",
    "    \n",
    "    post = tf.math.reduce_sum(y[i], axis=[0, -1])\n",
    "    ax2.imshow(post)#, vmin=0, vmax=1)\n",
    "    ax2.set_title('post')\n",
    "    \n",
    "    im = ax3.imshow(hot_map[i, 0, :, :, 0], vmin=0, vmax=5)\n",
    "    ax3.set_title('anomaly')\n",
    "    plt.colorbar(im, ax=ax3, shrink=0.3)\n",
    "    \n",
    "    plt.subplots_adjust(top=1.25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_score = ddm.hot_detect(model['gamma'], basis=X, test=y, rmse=model['rmse'],\n",
    "                         normalization=normalization, mean=model['mean'], std=model['std'],\n",
    "                         reduce=True)\n",
    "plt.hist(hot_score.numpy(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_probs['loc_0386.p'].shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_loc_series(loc_array, timestep=10):\n",
    "    steps = np.arange(len(loc_array)-timestep-1, step=1)\n",
    "    X = []\n",
    "    y = []\n",
    "    for step in steps:\n",
    "        X += [loc_array[step:step+timestep]]\n",
    "        y += [loc_array[step+timestep+1]]\n",
    "      \n",
    "    X = np.stack(X)\n",
    "    X = tf.convert_to_tensor(X, dtype=float)\n",
    "    X = tf.reshape(X, [X.shape[0], X.shape[1], X.shape[2], X.shape[3], 1])\n",
    "    \n",
    "    y = np.stack(y)\n",
    "    y = tf.convert_to_tensor(y, dtype=float)\n",
    "    y = tf.reshape(y, [y.shape[0], 1, y.shape[1], y.shape[2], 1])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = expand_loc_series(location_probs['loc_0386.p'])\n",
    "\n",
    "hot_score = ddm.hot_detect(model['gamma'], basis=X_test, test=y_test, rmse=model['rmse'],\n",
    "                           normalization=normalization, mean=model['mean'], std=model['std'],\n",
    "                           reduce=True)\n",
    "\n",
    "plt.scatter(np.arange(hot_score.shape[0]), hot_score.numpy())\n",
    "plt.show()\n",
    "\n",
    "timestep = 10\n",
    "for i in np.arange(len(location_probs['loc_0386.p'])-timestep-1, step=timestep):\n",
    "    plt.imshow(np.log(location_probs['loc_0386.p'][i]))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "timestep = 10\n",
    "\n",
    "for k, v in tqdm(location_probs.items(), total=len(location_probs)):\n",
    "    \n",
    "    X_test, y_test = expand_loc_series(v, timestep=timestep)\n",
    "    hot_score = ddm.hot_detect(model['gamma'], basis=X_test, test=y_test, rmse=model['rmse'],\n",
    "                           normalization=normalization, mean=model['mean'], std=model['std'],\n",
    "                           reduce=True)\n",
    "    \n",
    "    results[k] = hot_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ddm_results.p', 'wb') as f: \n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
